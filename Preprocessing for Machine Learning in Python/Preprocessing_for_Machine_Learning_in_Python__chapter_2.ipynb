{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocessing for Machine Learning in Python _chapter 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF9D3R6K68_9"
      },
      "source": [
        "# Trần Triệu Tuân - ID: 1902023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASbxtURZ8D6Q"
      },
      "source": [
        "#**Preprocessing for Machine Learning in Python from DataCamp**\n",
        "#Chapter 3: Feature Engineering\n",
        "\n",
        "**----------------------------------------------------------------------**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R799UM6y8ZA8"
      },
      "source": [
        "# Set up and training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L5hArqp7Eax"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLwc3WDMSKiF"
      },
      "source": [
        "**Loading and scale hiking.json data on datacamp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "3100ClEd7Ivw",
        "outputId": "5b91b4bf-9960-4bfb-a1f0-9e1a431c6672"
      },
      "source": [
        "hiking = pd.read_json(\"https://assets.datacamp.com/production/repositories/1816/datasets/4f26c48451bdbf73db8a58e226cd3d6b45cf7bb5/hiking.json\")\n",
        "hiking.dropna(subset = [\"Length\"], inplace=True)\n",
        "hiking.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prop_ID</th>\n",
              "      <th>Name</th>\n",
              "      <th>Location</th>\n",
              "      <th>Park_Name</th>\n",
              "      <th>Length</th>\n",
              "      <th>Difficulty</th>\n",
              "      <th>Other_Details</th>\n",
              "      <th>Accessible</th>\n",
              "      <th>Limited_Access</th>\n",
              "      <th>lat</th>\n",
              "      <th>lon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B057</td>\n",
              "      <td>Salt Marsh Nature Trail</td>\n",
              "      <td>Enter behind the Salt Marsh Nature Center, loc...</td>\n",
              "      <td>Marine Park</td>\n",
              "      <td>0.8 miles</td>\n",
              "      <td>None</td>\n",
              "      <td>&lt;p&gt;The first half of this mile-long trail foll...</td>\n",
              "      <td>Y</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B073</td>\n",
              "      <td>Lullwater</td>\n",
              "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
              "      <td>Prospect Park</td>\n",
              "      <td>1.0 mile</td>\n",
              "      <td>Easy</td>\n",
              "      <td>Explore the Lullwater to see how nature thrive...</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B073</td>\n",
              "      <td>Midwood</td>\n",
              "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
              "      <td>Prospect Park</td>\n",
              "      <td>0.75 miles</td>\n",
              "      <td>Easy</td>\n",
              "      <td>Step back in time with a walk through Brooklyn...</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B073</td>\n",
              "      <td>Peninsula</td>\n",
              "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
              "      <td>Prospect Park</td>\n",
              "      <td>0.5 miles</td>\n",
              "      <td>Easy</td>\n",
              "      <td>Discover how the Peninsula has changed over th...</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B073</td>\n",
              "      <td>Waterfall</td>\n",
              "      <td>Enter Park at Lincoln Road and Ocean Avenue en...</td>\n",
              "      <td>Prospect Park</td>\n",
              "      <td>0.5 miles</td>\n",
              "      <td>Easy</td>\n",
              "      <td>Trace the source of the Lake on the Waterfall ...</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Prop_ID                     Name  ... lat lon\n",
              "0    B057  Salt Marsh Nature Trail  ... NaN NaN\n",
              "1    B073                Lullwater  ... NaN NaN\n",
              "2    B073                  Midwood  ... NaN NaN\n",
              "3    B073                Peninsula  ... NaN NaN\n",
              "4    B073                Waterfall  ... NaN NaN\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBATXBWESbN_"
      },
      "source": [
        "**Loading and scale volunteer.csv data on datacamp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "id": "9RBoCBqm-Ow6",
        "outputId": "67b51399-8b3d-4d7c-a4d9-00e8e9f92d08"
      },
      "source": [
        "volunteer = pd.read_csv(\"https://assets.datacamp.com/production/repositories/1816/datasets/668b96955d8b252aa8439c7602d516634e3f015e/volunteer_opportunities.csv\")\n",
        "# drop NaN values of category_desc column\n",
        "volunteer.dropna(subset = [\"category_desc\"], inplace=True)\n",
        "# print head of dataset\n",
        "volunteer.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>opportunity_id</th>\n",
              "      <th>content_id</th>\n",
              "      <th>vol_requests</th>\n",
              "      <th>event_time</th>\n",
              "      <th>title</th>\n",
              "      <th>hits</th>\n",
              "      <th>summary</th>\n",
              "      <th>is_priority</th>\n",
              "      <th>category_id</th>\n",
              "      <th>category_desc</th>\n",
              "      <th>amsl</th>\n",
              "      <th>amsl_unit</th>\n",
              "      <th>org_title</th>\n",
              "      <th>org_content_id</th>\n",
              "      <th>addresses_count</th>\n",
              "      <th>locality</th>\n",
              "      <th>region</th>\n",
              "      <th>postalcode</th>\n",
              "      <th>primary_loc</th>\n",
              "      <th>display_url</th>\n",
              "      <th>recurrence_type</th>\n",
              "      <th>hours</th>\n",
              "      <th>created_date</th>\n",
              "      <th>last_modified_date</th>\n",
              "      <th>start_date_date</th>\n",
              "      <th>end_date_date</th>\n",
              "      <th>status</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Community Board</th>\n",
              "      <th>Community Council</th>\n",
              "      <th>Census Tract</th>\n",
              "      <th>BIN</th>\n",
              "      <th>BBL</th>\n",
              "      <th>NTA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5008</td>\n",
              "      <td>37036</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>Web designer</td>\n",
              "      <td>22</td>\n",
              "      <td>Build a website for an Afghan business</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bpeace</td>\n",
              "      <td>37026</td>\n",
              "      <td>1</td>\n",
              "      <td>5 22nd St\\nNew York, NY 10010\\n(40.74053152272...</td>\n",
              "      <td>NY</td>\n",
              "      <td>10010.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5008</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 14 2011</td>\n",
              "      <td>January 25 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5016</td>\n",
              "      <td>37143</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>Urban Adventures - Ice Skating at Lasker Rink</td>\n",
              "      <td>62</td>\n",
              "      <td>Please join us and the students from Mott Hall...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Street Project</td>\n",
              "      <td>3001</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>10026.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5016</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 19 2011</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>January 29 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5022</td>\n",
              "      <td>37237</td>\n",
              "      <td>500</td>\n",
              "      <td>0</td>\n",
              "      <td>Fight global hunger and support women farmers ...</td>\n",
              "      <td>14</td>\n",
              "      <td>The Oxfam Action Corps is a group of dedicated...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Strengthening Communities</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Oxfam America</td>\n",
              "      <td>2170</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>2114.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5022</td>\n",
              "      <td>ongoing</td>\n",
              "      <td>0</td>\n",
              "      <td>January 21 2011</td>\n",
              "      <td>January 25 2011</td>\n",
              "      <td>February 14 2011</td>\n",
              "      <td>March 31 2012</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5055</td>\n",
              "      <td>37425</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Stop 'N' Swap</td>\n",
              "      <td>31</td>\n",
              "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Environment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Office of Recycling Outreach and Education</td>\n",
              "      <td>36773</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>10455.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5055</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>February 01 2011</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>February 05 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5056</td>\n",
              "      <td>37426</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>Queens Stop 'N' Swap</td>\n",
              "      <td>135</td>\n",
              "      <td>Stop 'N' Swap reduces NYC's waste by finding n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Environment</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Office of Recycling Outreach and Education</td>\n",
              "      <td>36773</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NY</td>\n",
              "      <td>11372.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>/opportunities/5056</td>\n",
              "      <td>onetime</td>\n",
              "      <td>0</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>January 28 2011</td>\n",
              "      <td>February 12 2011</td>\n",
              "      <td>February 12 2011</td>\n",
              "      <td>approved</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   opportunity_id  content_id  vol_requests  ...  BIN BBL  NTA\n",
              "1            5008       37036             2  ...  NaN NaN  NaN\n",
              "2            5016       37143            20  ...  NaN NaN  NaN\n",
              "3            5022       37237           500  ...  NaN NaN  NaN\n",
              "4            5055       37425            15  ...  NaN NaN  NaN\n",
              "5            5056       37426            15  ...  NaN NaN  NaN\n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr-IGH3W_C-N"
      },
      "source": [
        "# Encoding categorical variables - binary\n",
        "\n",
        "\n",
        "*   Take a look at the **hiking** dataset. There are several columns here that need encoding, one of which is the **Accessible** column, which needs to be encoded in order to be modeled. **Accessible** is a binary feature, so it has two values - either Y or N - so it needs to be encoded into 1s and 0s. Use **scikit-learn's LabelEncoder**  method to do that transformation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAS8Qnll7RZZ",
        "outputId": "568e8d01-8391-42b9-8d7f-1e56298a0c86"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "enc = preprocessing.LabelEncoder()\n",
        "\n",
        "# Apply the encoding to the \"Accessible\" column\n",
        "hiking['Accessible_enc'] = enc.fit_transform(hiking.Accessible)\n",
        "\n",
        "# Compare the two columns\n",
        "print(hiking[['Accessible', 'Accessible_enc']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Accessible  Accessible_enc\n",
            "0          Y               1\n",
            "1          N               0\n",
            "2          N               0\n",
            "3          N               0\n",
            "4          N               0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVFbc-5S_Fq6"
      },
      "source": [
        "# Encoding categorical variables - one-hot\n",
        "\n",
        "\n",
        "*   One of the columns in the **volunteer** dataset, **category_desc**, gives \n",
        "category descriptions for the volunteer opportunities listed. Because it is a categorical variable with more than two categories, we need to use one-hot encoding to transform this column numerically. Use *Pandas'* **get_dummies()**function to do so.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E5lTIAx88xq",
        "outputId": "c23104ae-516f-460a-dbce-a19d3c579f07"
      },
      "source": [
        "# Transform the category_desc column\n",
        "category_enc = pd.get_dummies(volunteer[\"category_desc\"])\n",
        "\n",
        "# Take a look at the encoded columns\n",
        "print(category_enc.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Education  ...  Strengthening Communities\n",
            "1          0  ...                          1\n",
            "2          0  ...                          1\n",
            "3          0  ...                          1\n",
            "4          0  ...                          0\n",
            "5          0  ...                          0\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3e4u89RCoy4"
      },
      "source": [
        "#3.3.1 Engineering numerical features – taking an average\n",
        "\n",
        "\n",
        "* A good use case for taking an aggregate statistic to create a new feature is to take the mean of columns. Here, you have a **DataFrame** of running times named **running_times_5k**. For each name in the dataset, take the mean of their 5 run times.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "_bCMKJbc96VU",
        "outputId": "03ce8ec6-d00b-445a-c6df-4388c1a8c781"
      },
      "source": [
        "# Create a list of the columns to average\n",
        "run_columns = ['run1', 'run2', 'run3', 'run4', 'run5']\n",
        "\n",
        "# Use apply to create a mean column\n",
        "running_times_5k[\"mean\"] = running_times_5k.apply(lambda row: row[run_columns].mean(), axis=1)\n",
        "\n",
        "# Take a look at the results\n",
        "print(running_times_5k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-43f6fe0e7995>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use apply to create a mean column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrunning_times_5k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_times_5k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrun_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Take a look at the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'running_times_5k' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvDsOtQ3CXXb"
      },
      "source": [
        "# 3.3.2 Engineering numerical features – datetime\n",
        "\n",
        "\n",
        "* There are several columns in the volunteer dataset comprised of datetimes. Let’s take a look at the **start_date_date** column and extract just the month to use as a feature for modeling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NdhyMT_CSOt",
        "outputId": "aac8adaa-29e9-4eb5-94fb-0d40518e2de4"
      },
      "source": [
        "volunteer[\"start_date_converted\"] = pd.to_datetime(volunteer[\"start_date_date\"])\n",
        " \n",
        "# Extract just the month from the converted column\n",
        "volunteer[\"start_date_month\"] = volunteer[\"start_date_converted\"].apply(lambda row: row.month)\n",
        " \n",
        "# Take a look at the converted and new month columns\n",
        "print(volunteer[['start_date_converted', 'start_date_month']].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  start_date_converted  start_date_month\n",
            "1           2011-02-01                 2\n",
            "2           2011-01-29                 1\n",
            "3           2011-02-14                 2\n",
            "4           2011-02-05                 2\n",
            "5           2011-02-12                 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJLf0WnkCeIK"
      },
      "source": [
        "# 3.4 Text classification\n",
        "\n",
        "$ P(A|B)= \\frac{P(B|A)P(A)}{P(B} $\n",
        "\n",
        "# Vectorizing text\n",
        "\n",
        "\n",
        "*   tf = term frequency\n",
        "*   idf = inverse documnent frequency \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pecRYA-qEH8_"
      },
      "source": [
        "**3.4.1 Engineering features from strings – extraction**\n",
        "\n",
        "\n",
        "*   The Length column in the hiking dataset is a column of strings, but contained in the column is the mileage for the hike. We’re going to extract this mileage using regular expressions, and then use a lambda in Pandas to apply the extraction to the DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9jo1YDdCZNp",
        "outputId": "95540a2b-b3c6-40c6-8c17-e46bd1c9190e"
      },
      "source": [
        "import re\n",
        "\n",
        "# Write a pattern to extract numbers and decimals\n",
        "def return_mileage(length):\n",
        "    pattern = re.compile(r\"\\d+\\.\\d+\")\n",
        "    \n",
        "    # Search the text for matches\n",
        "    mile = re.match(pattern, length)\n",
        "    \n",
        "    # If a value is returned, use group(0) to return the found value\n",
        "    if mile is not None:\n",
        "        return float(mile.group(0))\n",
        "        \n",
        "# Apply the function to the Length column and take a look at both columns\n",
        "hiking[\"Length_num\"] = hiking[\"Length\"].apply(lambda row: return_mileage(row))\n",
        "print(hiking[[\"Length\", \"Length_num\"]].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Length  Length_num\n",
            "0   0.8 miles        0.80\n",
            "1    1.0 mile        1.00\n",
            "2  0.75 miles        0.75\n",
            "3   0.5 miles        0.50\n",
            "4   0.5 miles        0.50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnbhxJd0RtM0"
      },
      "source": [
        "**3.4.2 Engineering features from strings – tf/idf**\n",
        "\n",
        "\n",
        "*   Let’s transform the volunteer dataset’s title column into a text vector, to use in a prediction task in the next exercise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdgf9hYoAOb1",
        "outputId": "aaad054b-cd4b-4152-da7b-b94354c046f3"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Take the title text\n",
        "title_text = volunteer[\"title\"]\n",
        "\n",
        "# Create the vectorizer method\n",
        "tfidf_vec = TfidfVectorizer()\n",
        "\n",
        "# Transform the text into tf-idf vectors\n",
        "text_tfidf = tfidf_vec.fit_transform(title_text)\n",
        "text_tfidf.toarray()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQmX26zyJP35",
        "outputId": "12d5f395-4e9b-4404-d793-dbc44d6cbf2b"
      },
      "source": [
        "\n",
        "text_tfidf.toarray().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(617, 1089)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRA-tU2BR31l"
      },
      "source": [
        "**3.4.3 Text classification using tf/idf vectors**\n",
        "\n",
        "\n",
        "*   Now that we’ve encoded the volunteer dataset’s title column into tf/idf vectors, let’s use those vectors to try to predict the category_desc column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDFsvTIgJcip",
        "outputId": "7ae70f8a-50d3-451e-8d47-36216b1f96e3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "# Split the dataset according to the class distribution of category_desc\n",
        "y = volunteer[\"category_desc\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_tfidf.toarray(), y, stratify=y)\n",
        "\n",
        "# set GaussianNB to nb variables\n",
        "nb=GaussianNB()\n",
        "# Fit the model to the training data\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Print out the model's accuracy\n",
        "print(nb.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5548387096774193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeTuWnmDKa3h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}